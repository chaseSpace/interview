# 系统设计基础

## 系统设计的三大目标

- 高性能（High Performance）
- 高可用（High Availability）
- 高扩展（High Scalability）

回答问题时，脑子里要先有一张“架构地图”。

### 高性能架构设计：核心目标是“快”

性能瓶颈的本质：CPU/内存/IO（磁盘 / 网络）。
引入的任何优化手段，本质都是在减少慢路径或提高资源利用率。

#### 解决CPU瓶颈

CPU瓶颈的本质是：算不过来。原因如下方面：

- 计算密集
    - 复杂业务逻辑
    - 大量加解密、压缩、正则、序列化/反序列化
- 上下文切换过多
    - 线程/协程数量失控
    - 锁竞争严重
- 单核瓶颈
    - 单线程模型
    - 某些热点逻辑无法并行

**解决思路（从软件到架构）**

1. 算法实现层
    - 采用更优化的算法降低时间复杂度
    - 避免重复计算（缓存中间结果）
    - 减少序列化、反射、动态解析
2. 并行化
    - 多线程/多协程
    - 分片并行：通过将数据或任务拆分成多个相互独立的分片并行处理，从而提升整体吞吐和 CPU 利用率，例如Map-Reduce。
    - CPU 绑定：CPU 绑定通过减少线程在不同核心之间迁移，提高 CPU cache 命中率，降低调度开销，从而提升吞吐和稳定性。
    - 线程池限流：限制并发执行的线程数，避免过度上下文切换和 CPU 争抢，使系统在高负载下保持可控和稳定。
3. 架构层
    - 水平扩展（Scale Out）：通过多节点部署无状态服务分散单节点CPU压力
    - 异步化：非关键逻辑异步处理（MQ / 任务队列）

#### 解决内存瓶颈

内存瓶颈的本质是：放不下 / 管不过来。有如下原因：

- 内存泄露
- GC 压力大
- 缓存命中率低
- 数据量过大

**解决思路**

1. 数据结构与对象管理

- 减少对象创建（对象池、复用）
- 使用紧凑数据结构（数组 > Map > 对象）
- 控制缓存大小（LRU / LFU）

2. 缓存设计

- 本地缓存（进程内）
- 分布式缓存（Redis）
- 热点数据缓存，冷数据回源

3. 架构层

- 读写分离（适合读多写少）
- 数据分片：单机内存放不下 → 水平拆分

#### 解决磁盘 I/O 瓶颈

磁盘 I/O 瓶颈的本质是：读写太慢。原因如下方面：

- 随机 I/O 多
- 磁盘访问频繁
- 大量同步写
- 索引设计不合理

**解决思路**

1. 减少磁盘访问
    - 缓存：Page Cache、Redis / 本地缓存。
    - 数据库设计合理索引，避免全表扫描

2. 顺序化 & 批量化
    - 顺序写（WAL / Append Log）
    - 批量写入（Batch）
    - 合并小 I/O

3. 架构层
    - SSD / NVMe
    - 数据冷热分离
    - 日志与数据分盘

#### 解决网络 I/O 瓶颈

网络 I/O 瓶颈 的本质：传得太慢 / 太多。原因如下方面：

- 底层I/O 模型不是最优：采用epoll+主从Reactor网络模型
- RPC 次数多
- 数据包大
- 跨机房调用
- 阻塞 IO

**解决思路**

1. 减少网络交互
    - 减少请求链路层级
    - 服务内聚，避免过度拆分

2. 提升网络效率
    - 压缩（gzip / snappy）
    - 二进制协议（Protobuf / messagepack）
    - 连接复用（KeepAlive / HTTP2）

3. 架构层
    - 就近访问（同机房 / 同可用区）
    - CDN（静态资源）
    - 异步调用

#### 小结

- CPU：减少计算 + 并行
- 内存：少对象 + 高命中缓存
- 磁盘：少 IO + 顺序化
- 网络：少交互 + 少数据

### 高可用架构设计：核心目标是“不挂”

高可用的目标不是“永不出错”，而是“出错了系统还能对外提供可接受的服务”。

#### 理论基础

1. CAP 定理

- C 一致性
- A 可用性
- P 分区容错性（分布式系统必须要）

提示：网络一定会出问题，实际是在 C 和 A 之间取舍。

2. BASE 定理

- Basically Available（基本可用）
  - 允许系统在出现故障时，损失部分可用性，但仍能对外提供基本服务。
- Soft State（软状态）
  - 系统中的数据状态可以在不同节点间存在中间状态。
- Eventually Consistent（最终一致）
  - 系统在经过一段时间后，最终能够达到一致状态。

**BASE 与 CAP 定理的关系**
   - BASE 定理提供了一种实际的折衷方案，通过接受最终一致性来换取系统高可用性
   - BASE 是对 CAP 中 AP 系统（可用性优先）的具体实现方式。

#### 具体技术实现方案

##### 1. 服务冗余（消除单点）

- 多实例部署：同一个服务部署多个实例，避免单点故障
- 负载均衡：通过负载均衡器（Nginx、HAProxy、SLB）将流量分发到多个实例
- 健康检查：定期检查服务实例健康状态，自动剔除异常实例
- 跨机房/跨区域部署：在多个机房或区域部署服务，应对机房级故障
- 多活架构：多个机房同时提供服务，实现异地多活

##### 2. 流量控制（保护系统）

- 限流：限制系统的请求处理速率，防止流量过载
  - 令牌桶算法：恒定速率放入令牌，请求获取令牌才能通过
  - 漏桶算法：恒定速率处理请求，多余请求被丢弃
  - 固定窗口：在固定时间窗口内限制请求数
  - 滑动窗口：更平滑的限流方式，避免临界问题
  - 分布式限流：基于 Redis 实现跨实例的限流
- 熔断：当服务出现故障时，快速失败，避免级联雪崩
  - 熔断器状态：关闭（正常）、打开（熔断）、半开（尝试恢复）
  - 熔断策略：错误率阈值、响应时间阈值、异常数阈值
  - 常见实现：Hystrix、Resilience4j、Sentinel
- 降级：在系统负载过高或服务异常时，牺牲部分功能保证核心功能可用
  - 功能降级：关闭非核心功能（如评论、推荐）
  - 读降级：返回缓存数据或默认值
  - 写降级：异步写入或降级存储

##### 3. 故障隔离（防止扩散）

- 资源隔离：不同服务使用独立的线程池、连接池、内存等资源
- 进程隔离：不同服务部署在不同进程或容器中
- 机房隔离：不同机房的服务独立部署，避免跨机房故障扩散
- 租户隔离：多租户系统按租户隔离资源
- 数据库隔离：核心业务与次要业务使用不同的数据库实例

##### 4. 超时与重试（提高容错）

- 超时控制：为所有远程调用设置合理的超时时间
  - 连接超时：建立连接的最大等待时间
  - 读取超时：等待响应的最大时间
  - 超时时间设置：根据业务容忍度和服务 SLA 确定
- 重试机制：在失败时自动重试，提高成功率
  - 重试策略：固定间隔、指数退避、随机退避
  - 重试次数：限制最大重试次数，避免无限重试
  - 幂等性：确保重试不会产生副作用
  - 重试触发条件：网络异常、超时、特定错误码

##### 5. 数据备份与恢复（保障数据）

- 数据库主从复制：主库写入，从库读取，实现读写分离
- 数据库集群：MySQL MGR、PostgreSQL Patroni、MongoDB Replica Set
- 定期备份：全量备份 + 增量备份
- 备份验证：定期验证备份的可用性
- 跨机房备份：备份数据存储到异地机房
- 快照备份：使用云服务的快照功能快速备份
- 数据恢复演练：定期演练数据恢复流程

##### 6. 缓存高可用（提升可用性）

- Redis 主从复制：主节点写入，从节点读取
- Redis Sentinel：自动故障检测和故障转移
- Redis Cluster：分布式集群，自动分片和故障转移
- 多级缓存：本地缓存 + 分布式缓存，降低对单点的依赖
- 缓存预热：系统启动时加载热点数据
- 缓存降级：缓存不可用时直接访问数据库

##### 7. 消息队列高可用（异步解耦）

- MQ 集群部署：Kafka、RabbitMQ、RocketMQ 都支持集群模式
- 消息持久化：消息持久化到磁盘，避免丢失
- 消息确认机制：确保消息被正确处理
- 死信队列：处理无法正常消费的消息
- 消息重试：消费失败时自动重试
- 消息幂等：确保重复消费不会产生副作用

##### 8. 监控与告警（及时发现问题）

- 监控指标：
  - 系统指标：CPU、内存、磁盘、网络
  - 应用指标：QPS、响应时间、错误率、吞吐量
  - 业务指标：订单量、注册量、支付成功率
- 监控工具：Prometheus + Grafana、Zabbix、ELK
- 日志收集：集中收集和分析日志（ELK Stack）
- 链路追踪：分布式追踪系统（Jaeger、Zipkin、SkyWalking）
- 告警策略：多级告警、告警聚合、告警收敛
- 告警渠道：邮件、短信、钉钉、Slack

##### 9. 灰度发布（降低发布风险）

- 蓝绿部署：同时维护两套环境，切换流量
- 金丝雀发布：先发布到少量实例，观察无问题后全量发布
- A/B 测试：同时运行多个版本，根据用户行为选择最优版本
- 滚动发布：逐个实例更新，保持服务始终可用
- 特性开关：通过配置控制功能开关，快速回滚

##### 10. 灾备演练（验证可用性）

- 混沌工程：主动注入故障，验证系统容错能力
- 故障演练：模拟服务宕机、网络故障、磁盘故障等场景
- 容灾演练：定期进行机房切换演练
- 应急预案：制定详细的故障处理流程
- 故障复盘：故障后进行复盘，总结经验教训

##### 11. 常见高可用指标

- 可用性：99.9%（8.76 小时/年）、99.99%（52.56 分钟/年）、99.999%（5.26 分钟/年）
- MTBF（Mean Time Between Failures）：平均故障间隔时间
- MTTR（Mean Time To Repair）：平均修复时间
- RPO（Recovery Point Objective）：恢复点目标，数据可容忍的最大丢失量
- RTO（Recovery Time Objective）：恢复时间目标，服务可容忍的最大停机时间

#### 小结

高可用架构设计是一个系统工程，需要从多个层面考虑：

1. **架构层面**：消除单点、多级冗余、异地多活
2. **技术层面**：限流、熔断、降级、超时、重试
3. **数据层面**：备份、复制、分片、缓存
4. **运维层面**：监控、告警、灰度、演练
5. **流程层面**：应急预案、故障复盘、持续改进

**关键原则**：
- 任何单点都会失败，必须消除单点
- 故障不可避免，但要限制影响范围
- 自动化优于人工操作
- 演练验证，不做纸上谈兵