# Redis 相关

本文内容部分摘自网络。

## 为什么 Redis 使用单线程

- 简单高效：单线程模型使 Redis 的开发和维护更加简单，不需要处理多线程带来的加锁、线程同步等复杂情况。
- 瓶颈不在 CPU：Redis 作为内存数据库，性能瓶颈主要在内存和网络带宽而非 CPU。
- 数据结构简单：Redis 的数据结构被专门设计得很简单高效，绝大部分操作的时间复杂度都是 O(1)，因此单线程已经足以应对大部分读写场景。
- I/O 多路复用：利用了操作系统提供的多路 I/O 复用 epoll 模型，可以高效地监听和处理多个客户端连接。

## 单线程的瓶颈

- 只能用一个 cpu 核(忽略后台线程)
- 如果 value 比较大，redis 的 QPS 会下降得很厉害，有时一个大 key 就可以拖垮
- QPS 难以更上一层楼

## 为什么 Redis 后来引入多线程

### Redis 4.x 的多线程

Redis 在 4.x 版本引入了多线程，用来**异步**执行`UNLINK`、`FLUSHALL ASYNC`、`FLUSHDB ASYNC`命令。
比如对于键的删除，我们一般不需要同步等待完成，而且删除大键是一个耗时操作。所以引入多线程是方便执行那些不需要同步返回的命令。

> [!NOTE]
> `UNLINK`是 Redis 4.0 新增的命令，用于异步删除一个（较大的）键，返回值是实际解除链接的键的数量。
> `DEL`命令仍然是同步删除一个键。

### Redis 6.x 的多线程 I/O

Redis 官方在 2020 年 5 月正式推出 6.0 版本，此版本正式引入了多线程 I/O。

首先要解释 **Redis 的单线程**：Redis 在处理客户端的请求时，包括获取 (socket 读)、解析、执行、内容返回 (socket 写)
等都由一个顺序串行的主线程处理。

随着硬件性能提升，Redis 的单线程性能瓶颈可能出现在网络 IO 的读写，也就是：单个线程处理网络读写的速度跟不上底层网络硬件的速度。
读写网络的 read/write 系统调用占用了 Redis 执行期间大部分 CPU 时间，瓶颈主要在于网络的 IO 消耗。
此时的优化方向：

- 提高网络 IO 性能，典型的实现比如使用 DPDK 来替代内核网络栈的方式。
- 使用多线程充分利用多核，提高网络请求读写的并行度，典型的实现比如 Memcached。

Redis 采用了第二种方式，即 Redis 采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度。
**需要注意的是**，Redis 多 IO 线程模型只用来处理网络读写请求，对于 Redis 的读写命令，依然是单线程处理。

**开启多线程**

Redis 6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 redis.conf 配置文件：

```shell
io-threads-do-reads yes
io-threads 4 # 建议为CPU核数-1
```

## Redis 的多路复用与 HTTP/2 有何不同

**应用层别不同**

HTTP/2 的多路复用发生在应用层，即在一个 TCP 连接上复用多条流。而 Redis 的多路复用发生在更底层的网络 IO 层，即在一个线程中同时处理多个客户端
socket 连接的 IO 操作。

**目的不同**

HTTP/2 多路复用的主要目的是减少 TCP 连接数，提高带宽利用率。Redis 的多路复用主要目的是保持单线程以及不必要的上下文切换开销。

## Redis 的事务实现

Redis 通过 MULTI、DISCARD、EXEC 和 WATCH 四个命令来实现事务功能，事务提供了一种"将多个命令
打包，然后一次性、按顺序地执行"的机制，并且事务在执行期间不被主动中断，一个事务从开始到执行
会经历以下三个阶段：

- WATCH：在事务开始前，用于监视一个或多个键，如果键的值发生了变化，则 EXEC 无法执行，事务中断（在 MULTI 前执行）
    - 事务中断后，WATCH 命令自动取消
    - 单个会话有效
- UNWATCH：取消 WATCH 对所有 key 的监视（在 MULTI 前执行）
- MULTI：标志着事务开始
- 输入其他命令：命令在服务器入列，命令语法错误会导致 EXEC 无法执行，即事务中断（所有命令都不执行）
- EXEC：服务器以先进先出的顺序执行命令，如果命令执行失败，则继续执行下一条命令，也不会回滚已执行的命令。
- DISCARD：取消一个事务（在 EXEC 前执行）

Redis 事务提供一致性和隔离性，但不提供原子性和持久性。

- **一致性**：指不会出现执行一半命令的情况。
- **隔离性**：指事务之间互不干扰，同时也不会在事务内插入其他命令。
- **原子性（X）**：指事务内的命令全部执行或都不执行，无法做到因为一条命令的运行时错误导致其他命令中断。
- **持久性（X）**：因为 Redis 的持久化都是异步的，做不到实时落盘（为了保证性能）。

## 内存淘汰机制

当 Redis 内存不够用时，它根据设置的淘汰策略来删除部分键。支持以下策略：

- no eviction：当内存使用超过配置时就会返回错误，不会驱逐任何键
- allkeys-lru：加入键的时候，如果过限，首先通过 LRU 算法驱逐最久没有使用的键
- voliatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键
- allkey-random：加入键的时候如果过限，从所有 key 中随机删除
- voliatile-random：加入键的时候如果过限，从设置了过期时间的键集合中随机删除
- voliatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键
- volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键
- allkeys-lfu：从所有键中驱逐使用频率最少的键

## 什么是缓存血崩

缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量的请
求。

**解决办法**

根据缓存血崩的原因执行不同的方案：

- Redis 宕机
    - 集群化或使用哨兵模式部署 Redis。
    - 开启持久化，保证重启后快速恢复缓存数据。
- 大量缓存同时失效
    - 在批量往 redis 存数据的时候，把每个 Key 的失效时间都加个随机值。
    - 或者设置热点数据永远不过期，有更新操作就更新缓存就可以了。
    - 在代码中实现本地缓存，避免请求全部落到数据库。
    - 接口限流。

## 什么是缓存穿透

请求的数据根本不存在，所以缓存 miss，请求一直落到数据库。此时如果请求量较大就会击垮数据库。

**解决办法**

- 添加参数校验。
- 缓存空值 key。

## 什么是缓存击穿

大量的请求同时查询一个 热 key 时，假设此时，这个 key 正好失效了，就会导致大量的请求都打到数据库上面去，这种现象我们称为击穿。
缓存击穿带来的问题就是会造成某一时刻数据库请求量过大，压力剧增。

**解决办法**

- 热点数据永不过期，由定时任务定期去刷新缓存。
- 互斥锁。在缓存 miss 后，从数据库加载缓存前，对操作加一个互斥锁。

## 什么是布隆过滤器

它由一个很长的二进制向量和一系列随机映射函数组成。布隆过滤器可以用于检索出一个元素是否在一个集合中，他的优点是空间效率和查询时间远远超过一般的算法。

**原理**

当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的
K 个点（offset），把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有
没有它了：如果这些点有任何一个 0，则被检元素一定不在；如果都是 1，则被检元素很可能在。这就
是布隆过滤器的基本思想。

**优点**

- 空间占用极小，因为本身不存储数据而是用比特位表示数据是否存在，某种程度具有保密的效果。
- 插入与查询操作的时间复杂度均为 O(k)，常数级别，k 表示散列函数执行次数。
- 散列函数之间可以相互独立，可以在硬件指令层加速计算。

**缺点**

- 误差（假阳性率）
- 无法删除

**具体使用**

从 Redis 4.0 开始,布隆过滤器作为一个模块被集成到 Redis 中。我们需要先下载并加载布隆模块。
布隆命令使用：

```shell
# 创建布隆过滤器   bloomFilter是键名   0.03 是允许的最大错误率   2000000是预期存储的元素个数
BF.RESERVE bloomFilter 0.03 2000000

# 添加元素
BF.ADD bloomFilter foo

# 添加多个元素
BF.MADD bloomFilter e1 e2

# 判断存在性
BF.EXISTS bloomFilter foo

# 判断多个元素的存在性
BF.MEXISTS {key} {item} {item} ...

# 查看布隆键信息，包含预设容量、实际占用、已插入元素数量等
BF.INFO {key}
```

若是 redis 3.x 版本，只能使用 redis 的 bitmap 来实现，比较麻烦。

## Redis 内存满了怎么办

## Monitor 命令有什么用

## Redis 集群相关

## Redis 用途汇总

- 缓存：加快数据访问速度。
- 限流：用做限流算法后端。（包括固定窗口、滑动窗口、漏桶算法、令牌桶）
- 消息队列：使用 List 和 Stream 实现简易队列。（不支持事务，仅适合用于存储非关键业务数据）
- 延迟队列：使用 ZSet+List 实现延迟队列。
- 分布式锁：使用`SETNX`命令实现。
- Session：使用 String 存储 Session。
- 排行榜：使用 ZSet 实现。
- 附近的人：使用 GeoHash 实现。
- 共同好友：使用 Set 结构的`SINTER`命令查询共同好友。
- 计数器：使用`INCR`命令实现。（例如统计同一 IP 一小时内发送短信次数、同一 IP 每秒请求数）

累计至少有 10 种用途。

### 缓存

Redis 实现缓存功能的基本原理是将常用的数据存储在内存中，以加快数据访问速度，并且可以通过设置过期时间来自动淘汰过期的缓存数据。
适合缓存的数据是那些更新频率较低、访问频率较高的数据，例如商品信息、用户信息等。

### 限流

限流是指通过对**一个时间窗口内的请求量**进行限制来保障系统的正常运行。限流有多种算法，分别用于不同的场景。

#### 固定窗口

又叫计数器算法，是一种简单方便的限流算法。主要通过一个支持原子操作的计数器来累计 1 秒内的请求次数，当 1
秒内计数达到限流阈值时触发拒绝策略。每过 1 秒，计数器重置为 0 开始重新计数。

**实现**  
在 Redis 中实现固定窗口限流可以使用计数器和过期时间结合的方式来实现。具体步骤如下：

- 设置计数器键：为每个需要进行限流的接口或操作设置一个对应的计数器键。
- 每次请求计数：每次有请求到达时，将计数器键的计数器值加一。
- 限流判断：判断计数器键的计数器值是否超过设定的阈值，如果超过，则拒绝该请求；否则允许该请求。
- 定时清零：Redis 的 TTL 功能会自动删除计数器键（等同于清零），以实现固定时间窗口的限流。

**缺点**  
主要是临界问题（突刺现象）。在窗口边界处，可能突然到达大量请求，但由于横跨两个窗口，导致被算法判定为合理。

#### 滑动窗口

滑动窗口算法是对固定窗口算法的一种改进。它将时间窗口分为多个子窗口，每个子窗口的大小相同，并且每个子窗口都对应一个计数器。
并且子窗口的间隔越小，滑动窗口的滚动就越平滑，限流的统计就会越精确。

**原理**

- 将固定时间窗口划分成多个小窗口
  - 滑动窗口算法在固定窗口的基础上,将一个固定时间窗口(如 1 分钟)划分成多个小窗口(如 6 个,每个 10 秒)。
- 每个小窗口维护独立的计数器
  - 每个小窗口都有自己独立的请求计数器,记录该小窗口内的请求数量。
- 窗口向前滑动
  - 当请求时间超过当前小窗口的最大时间时,整个时间窗口向前滑动一个小窗口。
  - 滑动时会丢弃第一个小窗口的计数,并在最后添加一个新的小窗口。
- 限流判断
  - 在整个时间窗口内,所有小窗口的请求计数之和不能超过设定的阈值,否则触发限流。

实现步骤略微复杂，此处不再描述。

#### 漏桶算法

漏桶算法（Leaky Bucket Algorithm）是一种常用的限流算法，它的原理类似于水桶中的漏洞。在漏桶算法中，请求会以恒定的速率被处理，
多余的请求将会被丢弃或者排队等待处理。这种算法**可以平滑地处理突发流量**，并且能够保证请求的处理速率不会超过事先设定的阈值。

**原理**

- 漏桶存储结构
  - 漏桶算法使用一个固定容量的漏桶存储请求，该漏桶以固定的速率漏水（放行请求），当有新请求到达时，都会被放入漏桶中等待放行。
- 请求处理
  - 每次有请求到达时，将请求放入漏桶中。如果漏桶已满，则拒绝该请求；否则允许该请求被处理。
- 漏桶处理
  - 漏桶以固定的速率进行漏水，当漏桶中的水满了时，多余的水将会被丢弃，即超出容量的请求将会被拒绝。
- 请求速率控制
  - 漏桶算法通过控制漏水速率来控制请求的处理速率，从而实现限流。

多数编程语言都提供了漏桶算法的实现，例如 Go 中的`go.uber.org/ratelimit`包。

#### 令牌桶

令牌桶算法（Token Bucket Algorithm）是一种常用的限流算法，它基于令牌桶数据结构来实现。该算法允许请求以一定的速率被处理，
超出速率的请求将被暂时存储或者直接拒绝。

**原理**

- 令牌桶存储结构
  - 令牌桶算法使用一个固定容量的令牌桶来存储令牌，令牌以固定的速率被添加到桶中。每个令牌代表一个可以被处理的请求。
- 令牌产生
  - 令牌桶以固定的速率生成令牌，并将令牌放入桶中。（生成令牌的速率决定了请求处理的速率）
- 请求处理（消耗令牌）
  - 每次有请求到达时，需要消耗令牌桶中的一个令牌才能处理该请求，若桶中令牌不足（说明流量过大），则请求将被延迟或拒绝。
- 请求速率控制
  - 通过调整令牌生成的速率来控制请求的处理速率。
- 允许突发流量
  - 算法允许一定程度的突发流量，因为桶中可以积累一定数量的令牌，从而在某个时间点允许大量数据的发送。

**与漏桶算法对比**

- 速率限制：令牌桶算法允许一定程度的突发传输，而漏桶算法则不允许突发，它强制数据以固定速率传输。
- 应对突发流量：令牌桶算法可以通过桶中积累的令牌应对瞬时的高流量，而漏桶算法则通过丢弃超出速率限制的数据包来避免拥塞。
- 应用场景：令牌桶算法适合需要一定速率限制但又希望允许短时间内的高流量传输的场景，如 HTTP 服务限流。漏桶算法适合需要严格控制流量速率，平滑流量的场景，
  如网络流量整形。

**优缺点**

- 令牌桶算法的优点在于它提供了更高的灵活性，允许一定程度的突发流量，但可能需要更复杂的实现逻辑。
- 漏桶算法的优点在于它简单且能够有效控制流量速率，但可能不够灵活，无法充分利用网络资源。

### 消息队列

消息队列是一种应用程序间异步通信的机制,它提供了缓存、解耦、削峰填谷和异步通信等功能,是构建分布式系统的重要组件之一。

消息队列选型一般使用 RabbitMQ、Kafka、RocketMQ 等，但这些服务相对 Redis 比较重（需要花钱和维护），一般用于关键业务数据，比如订单等。
而对于一些简单的、没有大量消息堆积的非关键业务场景，可以使用 Redis 实现 MQ。

Redis 中可以使用 List、Stream 和 Pub/Sub 来实现简单的消息队列功能。

#### List 实现 MQ

Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部(左边)或者尾部(右边)。
通过使用以下命令，可以实现一个简单的消息队列功能：

- LPUSH、RPOP 左进右出
- RPUSH、LPOP 右进左出

使用 RPOP、LPOP 命令消费数据时有个问题就是需要消费者轮询 Redis，所以可以使用 BRPOP、BLPOP 避免这个问题。

**实现 ACK 机制**

ACK 机制用来解决因为网络异常或消费者自身问题导致的消费失败情况。Redis 中可以使用双队列形式来实现 ACK 机制，步骤如下：

- 准备两个队列，其中存储数据的队列为 `queue1`，另一个队列命名为`queue1_bak`；
- 消费者使用 RPOPLPUSH 或 BRPOPLPUSH 命令消费数据（数据在弹出的同时将备份到另一个 bak 队列）；
- 消费者消费数据成功后，使用 LREM 命令销毁 bak 队列的数据；
- 启动定时任务，使用 LRANGE 命令读取队列数据，解析每条数据（需要包含产生时间戳），将超时消息（认为消费失败）重新入队 `queue1`；
  - 超时定义：因为使用 Redis 的队列的场景一般不存在大量消息堆积，所以我们可以估算一个消息产生到消费的时间差，比如 2
    分钟，可作为超时时间。
  - 因为这里的超时定义并不严谨，所以建议消息中包含唯一 id 实现幂等消费，否则可能会重复消费。

#### Stream 实现 MQ

Stream 是 Redis 5.0 引入的一种专门为消息队列设计的数据类型，Stream 是一个包含 0 个或者多个元素的有序队列，这些元素根据 ID
的大小进行有序排列。它实现了大部分消息队列的功能：

- 消息 ID 序列化生成；
- 消息遍历；
- 消息的阻塞和非阻塞读；
- Consumer Groups（消费组）；
  - 消费组的目的是通过多个消费者同时消费一个队列，实现负载均衡和容错。
  - 通过 XGROUP/XREADGROUP/XACK 实现消费者组功能；
- ACK 确认机制；
- 支持多播；
- 提供了很多消息队列操作命令；
- 提供了消息的持久化和主备复制功能*，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失；

常用命令：

```shell
# 插入数据(队列中每个元素由键值对的形式组成，不同元素可以包含不同数量的键值对)
# -- * 表示让 Redis 为插入的消息自动生成唯一ID，当然也可以自己定义。
# -- 消息 ID 由两部分组成：毫秒时间戳+序号。序号区分同一毫秒内的多条消息，从0开始。
> XADD stream_key * field1 value1 field2 value2 ...
"1645936602161-0"

# 读取数据
# -- COUNT 为元素个数；BLOCK 为阻塞读取，0表示永久阻塞，大于0表示阻塞时间（毫秒）
# -- 0-0 在读取消息的时候可以指定 ID，并从这个 ID 的下一条消息开始读取，0-0 则表示从第一个元素开始读取。
# -- 若要进行顺序消费，每次读取后要记住返回的消息ID，用做下次 XREAD 的消费ID参数。
# -- 注意，XREAD 只是读取队列消息，并不会从队列中删除元素。
> XREAD COUNT 1 BLOCK 0 STREAMS stream_key 0-0
1) 1) "stream_key"
   2) 1) 1) "1645936602161-0"
         2) 1) "field1"
            2) "value1"
            3) "field2"
            4) "value2"
            
# 新建消费组
# -- 其中cg1 为组名，0-0为起始消息ID，MKSTREAM 参数表示如果该消费组所属的流不存在时自动创建流。
> XGROUP CREATE stream_key cg1 0-0 MKSTREAM


# 使用一个新的stream测试消费组
# 在读取消息前插入一些数据
XADD bossStream * name zhangsan age 26
XADD bossStream * name lisi age 2
XADD bossStream * name bigold age 40

# 通过消费组读取消息（此命令与XREAD大同小异）
# -- 最后的参数">"，表示从尚未被消费的消息开始读取；
# -- 此时同组的其他消费者将不能读取到此消息，而是读取下一条"lisi"
# -- 注意：此时读取到的消息还未确认，所以还存在于stream。
> XREADGROUP GROUP cg1 consumer1 COUNT 1 BLOCK 0 STREAMS bossStream >
1) 1) "stream_key"
   2) 1) 1) "1645957821396-0"
         2) 1) "name"
            2) "zhangsan"
            3) "age"
            4) "26"

# 同组的其他消费者读取 "lisi"
> XREADGROUP GROUP 青龙门 consumer2 COUNT 1 BLOCK 0 STREAMS bossStream >
1) 1) "bossStream"
   2) 1) 1) "1645957838700-0"
         2) 1) "name"
            2) "lisi"
            3) "age"
            4) "2"

# 查看已读未确认消息
# -- Stream 内部有一个队列（pending List）保存每个消费者读取但是还没有执行 ACK 的消息。
# -- 返回结果中的 1) 表示未确认消息的个数。2) ~ 3) 表示所有消费者读取的消息最小和最大ID；
> XPENDING bossStream cg1
1) (integer) 2
2) "1645957821396-0"
3) "1645957838700-0"
4) 1) 1) "consumer1"
      2) "1"
   2) 1) "consumer2"
      2) "1"

# 查看 cg1.consumer1 读取的消息
# 用法：XPENDING key group [start end count] [consumer]
> XPENDING bossStream cg1 - + 10 consumer1
1) 1) "1645957821396-0"
   2) "consumer1"
   3) (integer) 3758384 # 自上次消息传递给消费者以来经过的毫秒数
   4) (integer) 1 # 该消息被传递的次数
   
# 确认消息
# -- 用法：XACK key group-key ID [ID ...]
# -- 消费成功后，ACK 通知 Streams，这条消息就会被删除。
> XACK bossStream cg1 1645957821396-0 1645957838700-0
(integer) 2
```

其他命令：

```shell
# 对流进行修剪，限制长度
# -- 例如XTRIM keyX MAXLEN ~ 100 表示保留最新的100条消息。~表示保留的消息数>=100即可，不用精确
XTRIM key MAXLEN [~] count 

XDEL key ID [ID ...]  # 删除流中的消息
XLEN key # 获取流包含的元素数量，即消息长度
XRANGE key start end [COUNT count] # 获取消息列表，会过滤已经删除的消息

# 删除组
XGROUP DESTROY mystream some-consumer-group
# 删除组内消费者
XGROUP DELCONSUMER mystream consumer-group-name myconsumer123

# 获取流的各项信息
XINFO STREAM mystream # 如消息数量、消费组数量、第一个和最后一个消息ID
XINFO GROUPS mystream
XINFO CONSUMERS mystream mygroup  # 含该消费者当前未确认的消息数量等信息
```

**参考**

- [别再用 Redis List 实现消息队列了，Stream 专为队列而生](https://www.cnblogs.com/uniqueDong/p/15959687.html)
- [Redis命令详解：Streams](https://jackeyzhe.github.io/2019/07/01/Redis命令详解：Streams/)

#### 发布订阅实现 MQ

> 严格来说 "发布/订阅" 只是一个广播机制，而不是真正的消息队列，因为不支持消息累积，从而无法实现 MQ 必备的异步通信功能。

Redis 通过 PUBLISH 、SUBSCRIBE 等命令实现了订阅与发布模式，这个功能提供两种信息机制，
分别是订阅/发布到频道和订阅/发布到模式（一个类似正则表达式的 Key）。

"发布/订阅"模式包含两种角色，分别是发布者和订阅者。订阅者可以订阅一个或者多个频道(channel)，
而发布者可以向指定的频道(channel)发送消息，所有订阅此频道的订阅者都会收到此消息。频道我们可以先理解为是个 Redis 的 key
值，而模式，可以理解为是一个类似正则匹配的 Key，只是个可以匹配给定模式的频道。这样就不需要显式的去订阅多个名称了，可以通过模式订阅这种方式，一次性关注多个频道。

**缺点**

由于 Redis 不会存储消息，所以只有在线的订阅者可以实时接收消息（并且没有 ACK 机制），离线订阅者会永远丢失消息。

**常用命令**

```shell
# 订阅N个频道
SUBSCRIBE channel [channel ...]
# 取消订阅
UNSUBSCRIBE [channel [channel ...]]

# 发布消息到指定频道
PUBLISH channel message

---

# （取消）订阅模式: 订阅符合模式的所有频道
# -- 模式支持 glob 风格的正则表达式，例如
#   - h?llo subscribes to hello, hallo and hxllo
#   - h*llo subscribes to hllo and heeeello
#   - h[ae]llo subscribes to hello and hallo, but not hillo
PSUBSCRIBE pattern [pattern ...]
PUNSUBSCRIBE [pattern [pattern ...]]
```

### 延迟队列

#### 概念

延迟队列是一种用于处理延迟消息的队列。它的主要特点是能够在指定的时间间隔后消费消息（执行任务）。基本上类似一个任务调度服务，只是处理的对象是消息而不是任务。

延迟队列至少需要保证以下几点：

- 消息传输可靠性：消息进入队列后，至少被消费一次
- 高可用：必须分布式部署
- 消息可删除：支持客户端随时删除消息
- 精度：支持秒级延迟
- 长延迟支持（可选）：比如 30 天的延迟

目前成熟的支持延迟队列的组件有 RocketMQ（阿里云，有开源版本）、CMQ（腾讯云）。如果不需要采用这么重的组件，可以使用 Redis 实现**
简易的
**延迟队列。

#### Redis 简易实现

Redis 可以使用一个 ZSet+两个 List 实现延迟队列，设计如下：

- ZSet：存储所有延迟消息，Score 为过期时间戳。用于筛选已经过期消息；
- List-delay：存储所有延迟消息，用于删除消息；
- List-timeout：存储所有过期消息，用于立即消费；

具体步骤如下：

- 创建定时消息：将消息与一个随机数打包后放入 ZSet 和 List-delay 中，并使用消息过期时间戳作为 ZSet 元素的分值；
  - 加入随机数才能允许添加重复的消息，ZSet 本身会对数据去重。
- 定时轮询 ZSet：每隔 2-5 秒，通过 Lua 脚本实现以下操作：
  - 使用`ZRANGEBYSCORE`命令取出 Score 小于等于当前时间的消息；
  - 在解包后推入另一个立即消费队列中（List-timeout）。
  - 使用`ZREM`和`LREM`命令删除 ZSet 和 List-delay 中已经转移的消息。
  - **@Note**：一般不需要每秒轮询 Redis，允许几秒的误差。
- 客户端调用删除消息 API：由于消息是加入随机数后存入 Redis 的，所以删除时需要先解包再对比，才能进行删除。这个过程需要 Lua
  脚本遍历 List-delay 完成：
  - 使用`LLEN`命令获取 List-delay 的长度
  - 使用 for 循环+下标的方式遍历 List-delay
  - 依次解包并对比消息，然后删除消息。
  - **@Note**：为什么不使用`ZSCAN`遍历 ZSet 来对比消息？
    - 因为 ZSet 键正在使用，其可能无限增长，遍历它的结束时间不确定。
- 客户端监听 List-timeout 队列：接收并执行时间误差在可接受范围内的消息。
  - 消息体内应该包含执行时间戳。
  - 客户端接收到的消息可能因为某些原因是一个过期时间较长的消息，因此在消费前需要判断过期时间较长的消息是否有必要消费。

此方案实现的延迟队列只能适用于十万级的消息堆积量（笔者推测），因为最耗时的步骤是`ZRANGEBYSCORE`命令，其时间复杂度为
O(log(N)+M)，其中 N 是 ZSet 中元素的数量，M 是分数范围内的成员数量。若 ZSet 中堆积的消息量巨大，会导致 Lua
脚本耗时过长，从而造成延迟消息的误差增大。

> [!NOTE]
> 实践中如果使用 Redis 实现延迟队列，除了必要的测试用例，笔者还建议使用单独的 Redis 实例作为延迟队列专用存储（集群架构+持久化），
> 避免消息堆积过多导致部分操作耗时过长影响其他业务。

**Redisson 实现**

[Redisson][0] 是 Java 实现的一个 22k+星星的 Redis 客户端，它不止于客户端，还基于 Redis 实现了许多功能。它的延迟队列实现基于以上思路进行了优化，
主要是使用客户端定时任务组件取代了对 ZSet 的轮询。具体来说就是，在推送消息时判断消息是否最旧的消息，是就把消息的时间戳发布到一个
channel，
客户端会订阅 channel，若时间戳即将到期（<=10ms），则将准备过期（<=10ms）的消息推送到立即消费队列中，否则启动一个内部的定时器，到期后执行相同逻辑。
此外，Redisson 在启动时和转移消息时也会将 ZSet 中的第一个消息的时间戳发布到 channel，保证下一次的消息转移。

对比来说，轮询的策略是稳定且简单的，但可能对 Redis 会产生较多无效的访问并且存在几秒误差（一般业务能接受）。而 Redisson
的客户端定时器策略需要基于一个发布订阅模式，实现会更精确，但也更为复杂。如果使用非 Java 语言实现延迟队列，可以参考以上两种方案。

**RocketMQ**

在开源产品 RocketMQ 中，支持的是 18 个级别的延迟消息（从 1s，5s 到最多 2h），其中内部也是一般采用一个单线程的定时器扫描不同延迟级别的内部队列，
将到期的消息重新放入到对应的立即消费队列中。但 RocketMQ 在阿里云的云上版本中，支持了任意级别的延迟消息，并且支持分布式部署，其中为了实现更大规模的消息，
内部应当使用了更复杂的架构设计。

**参考**

- [【分布式技术专题】RocketMQ 延迟消息实现原理和源码分析](https://juejin.cn/post/6997370258507956232)
- [ZRANGEBYSCORE](http://doc.redisfans.com/sorted_set/zrangebyscore.html)
- [redisson 原理](https://blog.csdn.net/m0_37893244/article/details/132224928)

### 分布式锁

分布式锁是一种在分布式系统中用于协调多个进程（中的线程）对共享资源访问的同步机制。它确保在同一时间内只有一个进程（中的线程）可以执行某个操作或访问某个资源，
从而避免并发访问导致的数据不一致问题。

**实现方式**

- 基于数据库的唯一索引：通过插入带有唯一索引的数据来实现锁的功能。
- 基于 Redis：使用`SETNX`命令实现，**最常使用**。
  - 设置的值通常是一个线程本地的唯一标识符，在删除时需要通过 Lua 脚本做到防误删。
  - Redis 官方推荐的 Go 分布式锁实现：[Redsync](https://github.com/go-redsync/redsync)，支持防死锁、防误删。
- 基于 ZooKeeper：通过创建一个临时节点来实现。
- 基于 etcd 实现：通过 Key 的 Revision 属性和租约机制来实现，Watch 机制帮助客户端重试。
  - Go 客户端提供锁实现。
- 基于 Consul 实现：使用 Key 的 Acquire 和 Release 接口来实现。
  - Go 客户端提供锁实现。

**参考**

- [Zookeeper 分布式锁实现原理](https://www.runoob.com/w3cnote/zookeeper-locks.html)
- [etcd 分布式锁的实现原理](https://juejin.cn/post/7062900835038003208)
- [consul 实现分布式锁](https://www.cnblogs.com/jiujuan/p/10527786.html)

### Session 存储

Session 是指用户登录后的请求凭据，用来验证用户身份。

**简单实现**

1. 首次首次访问网站时，服务器为用户创建一个唯一的 Session ID，通常是一个长随机字符串，并保存在Redis Key中。服务器将这个Session
   ID 发送给客户端，后者在下次请求时带上这个 Session ID（通过Header或Cookie）。
2. 在后续请求中，客户端将 Session ID 发送给服务器，服务器从Redis中根据 Session ID 找到对应的会话Key，然后返回用户会话信息。
3. 其中某些请求可能需要更新用户会话信息，比如修改用户资料，添加商品到购物车等，服务器会在找到对应的会话Key后，更新会话信息。

### 排行榜

使用ZSet可以轻松实现排行榜功能。

实现步骤：

- 使用有序集合存储排行榜数据，将每个成员作为排行榜中的一个项，分数作为该项的分数，例如，用户ID作为成员，分数为用户的得分。
- 使用`ZADD`命令将成员及其分数添加到有序集合中。
- 使用`ZREVRANGE`命令按照分数从高到低的顺序获取排行榜数据。
- 使用`ZREVRANK`命令获取某个成员的排名（高到低，从0开始）。
- 使用`ZREM`命令删除排行榜中的某个成员。
- 使用`ZCARD`命令获取排行榜中的成员数量。
- 使用`ZCOUNT`命令获取某个分数范围内的成员数量。
- 使用`ZINCRBY`命令更新某个成员的分数。
- 使用`ZSCORE`命令获取某个成员的分数。

**相同分数问题**

在排行榜中比较常见的一个问题就是，相同分数的成员排序问题，大部分业务场景都要求相同分数的成员按照更新时间先后排序。
此时在取出榜单列表后（通常是topN），单独查询相同分数的成员的更新时间，然后对<u>它们</u>重新排序。

### 附近的人

**业务说明**

这是一个常见的业务需求，比如微信中的“附近的人”功能，以及房产APP中查看附近的房源。
如果业务数据量较大（百万加），最好直接使用数据库或搜索引擎来实现，毕竟很多情况下这些数据都是存在数据库中的（Redis存储和计算压力较大），比如Solr、ES、PgSQL、MySQL和MongoDB。
如果数据量不高（万级）或要求实时性，可以使用Redis的Geo模块来实现。

> [!NOTE]
> 使用Redis的另一个限制是，不支持二次排序。
> 在海量数据的Geo查询场景中，一般会使用GeoHash优化查询（再附加其他条件），然后在业务层加上缓存，即可实现功能。

**实现方式**

自Redis v3.2起开始支持Geo模块。

- 使用`GEOADD`命令将给定的位置对象（纬度、经度、名字）添加到指定的key;
- 使用`GEORADIUS`命令获取**指定经纬度**的半径范围内的多个位置对象;
  - 支持结果集从近到远或反向排序；
  - 支持返回每个位置对象与指定位置之间的距离；
  - 支持返回每个位置对象的经纬度；
- 使用`GEORADIUSBYMEMBER`命令获取**指定位置对象**的半径范围内的多个位置对象，并且按照距离排序。

以上命令即可实现【附近的人】功能。以下为辅助命令：

- 使用`GEOPOS`命令获取给定位置对象的经度和纬度;
- 使用`GEODIST`命令获取两个给定位置之间的距离；
- 使用`GEOHASH`命令获取一个或多个给定位置对象的Geohash值。

**简单原理**

Redis的GEO数据结构是使用ZSet+GeoHash来实现的，它将位置对象存储在ZSet中，分数为从经纬度转换来的GeoHash值。

**参考**

- [Redis 到底是怎么实现“附近的人”这个功能的呢](https://juejin.cn/post/6844903966061363207)
- [GeoHash+Mysql 处理地理位置](https://juejin.cn/post/7113004754149572639)
- [揭开附近的“人”神秘面纱：初识GeoHash算法](https://juejin.cn/post/7255220627795525693?from=search-suggest)

### 共同好友

Set结构可以使用`SINTER`命令求交集的方式获取共同好友，但实践中较少使用。这是因为用户通常具有较多属性，比如等级等等。
业务通常不仅需要查出共同好友，还要按照某个属性排序，这个时候Redis是无法实现的，通常都是使用数据库如MySQL来实现。
如果查询频率高，可以将交集缓存到Redis中，然后在源数据变更的时候，清除缓存。

Redis的另一个局限是数据通常只是作为数据库的缓存，若用于存储好友列表，还要保证与数据库的数据一致性，这个实现起来也很麻烦。
所以实践中，**Set结构只用于查询仅Redis存储的数据的交集**。

### 计数器

**业务场景**

比如统计网页一小时访问量，单个IP的访问次数，对单个用户的发送短信次数等。

**实现**

Redis提供`INCR`和`INCRBY`命令，可以很方便的实现计数器功能。若要同时使用统计功能，则可以使用Redis的ZSet结构来存储数据，
然后使用`ZINCRBY`命令来更新计数。比如查询上一小时内访问量Top 10的IP列表（Key名标识一个小时），使用`ZREVRANGE`命令即可。

[0]: https://github.com/redisson/redisson/tree/master